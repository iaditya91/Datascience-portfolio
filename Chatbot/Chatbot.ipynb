{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import os\n",
    "import random\n",
    "human_txt_path = '/kaggle/input/rdany-conversations/human_text.txt'\n",
    "robot_txt_path = '/kaggle/input/rdany-conversations/robot_text.txt'\n",
    "\n",
    "# Storing txt content as lists\n",
    "with open(human_txt_path, 'r', encoding = 'utf-8') as f:\n",
    "    human_lines = f.read().split('\\n')\n",
    "\n",
    "with open(robot_txt_path, 'r', encoding = 'utf-8') as f:\n",
    "    robot_lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(robot_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning the data\n",
    "1. Removing the non-speaking words like [start], [silent] from the texts. Removing emotes and symbols characters from the texts. <br>\n",
    "2. Creating the human-bot response pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_lines = [re.sub(r'\\[\\w+\\]','hi',line) for line in human_lines]\n",
    "human_lines = [' '.join(re.findall(r'\\w+', line)) for line in human_lines]\n",
    "\n",
    "robot_lines = [re.sub(r'\\[\\w+\\]','',line) for line in robot_lines]\n",
    "robot_lines = [' '.join(re.findall(r'\\w+', line)) for line in robot_lines]\n",
    "\n",
    "pairs = list(zip(human_lines, robot_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "Taking 400 pair of human-responses responses and adding <START> and <STOP> tags to the bot responses for the machine to identify the end of string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = []\n",
    "target_txt = []\n",
    "\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "for line in pairs[:400]:\n",
    "    input_, target_ = line[0], line[1]\n",
    "    input_txt.append(input_)\n",
    "    target_ = ' '.join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_))\n",
    "    target_ = '<START> ' + target_ + ' <STOP>'\n",
    "    target_txt.append(target_)\n",
    "    \n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_):\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "    for token in target_.split():\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3192\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "print(num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding indexes to the vocabulary and storing it in dictonary of input and target respectivly.\n",
    "\n",
    "input_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_dict = {token: index for index, token in input_dict.items()} \n",
    "reverse_target_dict = {token: index for index, token in target_dict.items()} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", human_line)) for human_line in input_txt])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", robot_line)) for robot_line in target_txt])\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_txt), max_encoder_seq_length, num_encoder_tokens), dtype = 'float32')\n",
    "decoder_input_data = np.zeros((len(target_txt), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "decoder_target_data = np.zeros((len(target_txt), max_decoder_seq_length, num_decoder_tokens), dtype = 'float32')\n",
    "\n",
    "for line, (input_, target_) in enumerate(zip(input_txt, target_txt)):\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_)):\n",
    "        encoder_input_data[line, timestep, input_dict[token]] = 1\n",
    "    for timestep, token in enumerate(target_.split()):\n",
    "        decoder_input_data[line, timestep, target_dict[token]] = 1\n",
    "        if timestep > 0:\n",
    "            decoder_target_data[line, timestep - 1 , target_dict[token]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "dimensionality = [1024, 512, 256]\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoder Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape = (None, num_encoder_tokens), name ='encoder_inputs')\n",
    "outputs = encoder_inputs\n",
    "encoder_states = []\n",
    "for j in range(len(dimensionality))[::-1]:\n",
    "    outputs, h, c = LSTM(dimensionality[j], return_state = True,dropout = 0.2, return_sequences = bool(j))(outputs)\n",
    "    encoder_states += [h,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'lstm/PartitionedCall:2' shape=(None, 256) dtype=float32>, <tf.Tensor 'lstm/PartitionedCall:3' shape=(None, 256) dtype=float32>, <tf.Tensor 'lstm_1/PartitionedCall:2' shape=(None, 512) dtype=float32>, <tf.Tensor 'lstm_1/PartitionedCall:3' shape=(None, 512) dtype=float32>, <tf.Tensor 'lstm_2/PartitionedCall:2' shape=(None, 1024) dtype=float32>, <tf.Tensor 'lstm_2/PartitionedCall:3' shape=(None, 1024) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decoder Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name = 'decoder_inputs')\n",
    "outputs = decoder_inputs\n",
    "output_layers = []\n",
    "\n",
    "for j in range(len(dimensionality)):\n",
    "    output_layers.append(\n",
    "        LSTM(dimensionality[len(dimensionality) - j - 1], return_sequences=True, return_state=True, dropout = 0.2)\n",
    "    )\n",
    "    outputs, dh, hc = output_layers[-1](outputs, initial_state=encoder_states[2*j:2*(j+1)])\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax',  name = 'decoder_dense')\n",
    "decoder_outputs = decoder_dense(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buidling the Model\n",
    "seq2seq_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "#Compiling\n",
    "seq2seq_model.compile(optimizer='adam', loss ='categorical_crossentropy', metrics = ['accuracy'], sample_weight_mode = 'temporal')\n",
    "\n",
    "#Training the Model with the created matrices\n",
    "seq2seq_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "seq2seq_model.save('/kaggle/working/bi_3stack_full_dataset.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: To save the h5 file created in /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/kaggle/working')\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'chat_bot.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Re-Creating the Model taking trained weights from the model saved above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 981)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 512), (None, 2535424     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 1003)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][4]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  3104768     input_2[0][0]                    \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1003)   514539      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,154,731\n",
      "Trainable params: 6,154,731\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "#s2s_model = load_model('/kaggle/input/chatbot-output/chat_bot_adam.h5')\n",
    "s2s_model = load_model('../input/bi-bot/bi_chat_bot_n.h5')\n",
    "\n",
    "s2s_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot iterate over a tensor with unknown first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8a28c32ce713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Creating Encoder model from inputs and input_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoder_outputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden_state1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_cell_state1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoder_outputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden_state2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_cell_state2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoder_outputs3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden_state3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_cell_state3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m       raise TypeError(\n\u001b[0;32m--> 512\u001b[0;31m           \"Cannot iterate over a tensor with unknown first dimension.\")\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot iterate over a tensor with unknown first dimension."
     ]
    }
   ],
   "source": [
    "#print(s2s_model.summary())\n",
    "# Creating Encoder model from inputs and input_states\n",
    "encoder_inputs = s2s_model.input[0]\n",
    "encoder_outputs1, enc_hidden_state1, enc_cell_state1 = s2s_model.layers[2].output\n",
    "encoder_outputs2, enc_hidden_state2, enc_cell_state2 = s2s_model.layers[4].output\n",
    "encoder_outputs3, enc_hidden_state3, enc_cell_state3 = s2s_model.layers[6].output\n",
    "encoder_states = [enc_hidden_state1, enc_cell_state1, enc_hidden_state2, enc_cell_state2,  enc_hidden_state3, enc_cell_state3]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "print(encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====\n",
    "d_outputs = decoder_inputs\n",
    "decoder_input_states = []\n",
    "decoder_states = []\n",
    "\n",
    "for j in range(len(dimensionality))[::-1]:\n",
    "    current_state_inputs = [Input(shape=(dimensionality[j],)) for _ in range(2)]\n",
    "\n",
    "    temp = output_layers[len(dimensionality)-j-1](d_outputs, initial_state=current_state_inputs)\n",
    "\n",
    "    d_outputs, cur_states = temp[0], temp[1:]\n",
    "\n",
    "    decoder_states += cur_states\n",
    "    decoder_input_states += current_state_inputs\n",
    "\n",
    "decoder_outputs = decoder_dense(d_outputs)\n",
    "\n",
    "# Buidling decoder model from decoder inputs/input_states and output/output_states\n",
    "decoder_model = Model([decoder_inputs] + decoder_input_states, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cebb3111126f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(encoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     [(None, None, 3192)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  3531776     decoder_inputs[0][0]             \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 512),  1574912     lstm_3[1][0]                     \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 1024), 6295552     lstm_4[1][0]                     \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 3192)   3271800     lstm_5[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,674,040\n",
      "Trainable params: 14,674,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(decoder_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tesing the created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_response(user_input):\n",
    "    state_values = encoder_model.predict(user_input)\n",
    "    target_seq = np.zeros((1,1,num_decoder_tokens))\n",
    "    target_seq[0,0, target_dict['<START>']] = 1\n",
    "    bot_response = ''\n",
    "    start_flag = True\n",
    "    \n",
    "    while start_flag:\n",
    "        to_split = decoder_model.predict([target_seq] + state_values)\n",
    "        output_tokens, state_values = to_split[0], to_split[1:]\n",
    "        \n",
    "        # Choosing one with hightest probability\n",
    "        response_token_index = np.argmax(output_tokens[0, 0])\n",
    "        response_token = reverse_target_dict[response_token_index]\n",
    "\n",
    "        bot_response +=  response_token + \" \"\n",
    "        \n",
    "        if(response_token == '<STOP>'):\n",
    "            start_flag = False\n",
    "            \n",
    "        # Update target sequence\n",
    "        target_seq = np.zeros((1,1,num_decoder_tokens))\n",
    "        target_seq[0,0, response_token_index] = 1\n",
    "        \n",
    "    return bot_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    neg_responses = ('unhappy','no','sorry')\n",
    "    exit_commands = ('stop', 'pause', 'exit', 'goodbye', 'bye')\n",
    "    \n",
    "    # To initiate chat\n",
    "    def start_chat(self):\n",
    "        print(\"Bot: \", \"Hi, I'm a Friendly Bot. Would you like to chat with me?\\n\")\n",
    "        user_response = input()\n",
    "        #print(user_response)\n",
    "        \n",
    "        if user_response in self.neg_responses:\n",
    "            print(\"Bot: \",\"Ok, Have a great day!\")\n",
    "            return\n",
    "        self.chat(user_response)\n",
    "        \n",
    "    # To exit chat\n",
    "    def make_exit(self, reply):\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in reply:\n",
    "                print('Bot: ','Ok, have a great day!')\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # To continue chat till exit\n",
    "    def chat(self, reply):\n",
    "        while not self.make_exit(reply):\n",
    "            print(\"Bot: \",self.generate_response(reply) + '\\n')\n",
    "            reply = input()\n",
    "            print(\"User: \",reply)\n",
    "    \n",
    "            \n",
    "    # To generate a response using seq2seq model we built\n",
    "    def generate_response(self, user_input):\n",
    "        input_matrix = self.string_to_matrix(user_input)\n",
    "        chatbot_response = robot_response(input_matrix)\n",
    "        #Remove <START> and <STOP> tokens from chatbot_response\n",
    "        chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
    "        chatbot_response = chatbot_response.replace(\"<STOP>\",'')\n",
    "        return chatbot_response\n",
    "    \n",
    "    #Method to convert user input into a matrix\n",
    "    def string_to_matrix(self, user_input):\n",
    "        tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "        #print(\"tokens in ip: \", tokens)\n",
    "        # First input indicates one row\n",
    "        user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens),dtype='float32')\n",
    "        #print(user_input_matrix.shape)\n",
    "        for timestep, token in enumerate(tokens):\n",
    "            if token in input_dict:\n",
    "                # it can't able to handle other words out of trained human words\n",
    "                user_input_matrix[0, timestep, input_dict[token]] = 1\n",
    "                #print(user_input_matrix[0][timestep][input_dict[token]])\n",
    "        #print(user_input_matrix)\n",
    "        #print(user_input_matrix.shape)\n",
    "        return user_input_matrix\n",
    "\n",
    "chatbot = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot.start_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
